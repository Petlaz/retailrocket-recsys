{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de867e8",
   "metadata": {},
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a36469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded filtered data: (833463, 12)\n",
      "Loaded encoded item properties: (417053, 2272)\n",
      "Saved popularity model.\n",
      "Cleaned encoded_item_props shape: (417053, 2272)\n",
      "Computing similarity on subset: (8966, 2272)\n",
      "Saved item similarity matrix and subset items.\n",
      "Content-based filtering model built.\n",
      "Building KNN collaborative filtering model...\n",
      "Sparse user-item matrix shape: (80112, 38977), nnz=450427\n",
      "Saved KNN model.\n",
      "KNN collaborative filtering model built.\n",
      "Models and recommenders saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Paths (adjusted relative to notebooks/)\n",
    "ARTIFACTS_DIR = \"../artifacts\"\n",
    "EMBEDDINGS_DIR = os.path.join(ARTIFACTS_DIR, \"embeddings\")\n",
    "MODELS_DIR = os.path.join(ARTIFACTS_DIR, \"models\")\n",
    "INDICES_DIR = os.path.join(ARTIFACTS_DIR, \"indices\")\n",
    "\n",
    "DATA_FILTERED_PATH = \"../data/processed/df_filtered.pkl\"\n",
    "ENCODED_ITEM_PROPS_PATH = \"../data/processed/item_properties_encoded.pkl\"\n",
    "\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(INDICES_DIR, exist_ok=True)\n",
    "\n",
    "# Load filtered data\n",
    "df_filtered = pd.read_pickle(DATA_FILTERED_PATH)\n",
    "print(f\"Loaded filtered data: {df_filtered.shape}\")\n",
    "\n",
    "# Load encoded item properties\n",
    "encoded_item_props = pd.read_pickle(ENCODED_ITEM_PROPS_PATH)\n",
    "print(f\"Loaded encoded item properties: {encoded_item_props.shape}\")\n",
    "\n",
    "# 1. Popularity-based model\n",
    "popularity = df_filtered['itemid'].value_counts()\n",
    "popularity_df = popularity.reset_index()\n",
    "popularity_df.columns = ['itemid', 'count']\n",
    "popularity_df.to_parquet(os.path.join(MODELS_DIR, \"popularity_model.parquet\"))\n",
    "print(\"Saved popularity model.\")\n",
    "\n",
    "# 2. Content-Based Filtering\n",
    "# Clean encoded_item_props\n",
    "bool_cols = encoded_item_props.select_dtypes(include=['bool']).columns\n",
    "encoded_item_props[bool_cols] = encoded_item_props[bool_cols].astype(int)\n",
    "obj_cols = encoded_item_props.select_dtypes(include=['object']).columns\n",
    "encoded_item_props[obj_cols] = encoded_item_props[obj_cols].apply(pd.to_numeric, errors='coerce')\n",
    "encoded_item_props = encoded_item_props.fillna(0)\n",
    "encoded_item_props = encoded_item_props.select_dtypes(include=[np.number])\n",
    "print(f\"Cleaned encoded_item_props shape: {encoded_item_props.shape}\")\n",
    "\n",
    "# Restrict to top 10k popular items present in encoded_item_props\n",
    "top_items = popularity_df['itemid'].head(10000).tolist()\n",
    "subset_items = [i for i in top_items if i in encoded_item_props.index]\n",
    "encoded_subset = encoded_item_props.loc[subset_items]\n",
    "print(f\"Computing similarity on subset: {encoded_subset.shape}\")\n",
    "\n",
    "item_features = encoded_subset.values\n",
    "item_sim_matrix = cosine_similarity(item_features)\n",
    "\n",
    "# Save similarity matrix and subset item list\n",
    "sim_path = os.path.join(EMBEDDINGS_DIR, \"item_similarity_sub.npy\")\n",
    "np.save(sim_path, item_sim_matrix)\n",
    "encoded_subset.index.to_series().to_csv(os.path.join(EMBEDDINGS_DIR, \"item_similarity_sub_items.csv\"), index=False)\n",
    "print(f\"Saved item similarity matrix and subset items.\")\n",
    "\n",
    "def recommend_content_based(item_id, top_n=10):\n",
    "    if item_id not in encoded_subset.index:\n",
    "        return []\n",
    "    idx = encoded_subset.index.get_loc(item_id)\n",
    "    sim_scores = item_sim_matrix[idx]\n",
    "    top_indices = np.argsort(sim_scores)[::-1][1:top_n+1]\n",
    "    return encoded_subset.index[top_indices].tolist()\n",
    "\n",
    "print(\"Content-based filtering model built.\")\n",
    "\n",
    "# 3. KNN Collaborative Filtering\n",
    "print(\"Building KNN collaborative filtering model...\")\n",
    "\n",
    "user_cat = df_filtered['visitorid'].astype('category')\n",
    "item_cat = df_filtered['itemid'].astype('category')\n",
    "\n",
    "user_codes = user_cat.cat.codes.values\n",
    "item_codes = item_cat.cat.codes.values\n",
    "\n",
    "from collections import Counter\n",
    "pair_counts = Counter(zip(user_codes, item_codes))\n",
    "\n",
    "rows, cols, data = zip(*[(u, i, pair_counts[(u,i)]) for u,i in pair_counts.keys()])\n",
    "user_item_sparse = coo_matrix((data, (rows, cols)), shape=(user_cat.cat.categories.size, item_cat.cat.categories.size))\n",
    "\n",
    "print(f\"Sparse user-item matrix shape: {user_item_sparse.shape}, nnz={user_item_sparse.nnz}\")\n",
    "\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=11, n_jobs=-1)\n",
    "knn_model.fit(user_item_sparse.T)\n",
    "\n",
    "with open(os.path.join(MODELS_DIR, \"knn_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(knn_model, f)\n",
    "print(\"Saved KNN model.\")\n",
    "\n",
    "def recommend_collaborative_knn_sparse(item_id, top_n=10):\n",
    "    if item_id not in item_cat.cat.categories:\n",
    "        return []\n",
    "    item_idx = item_cat.cat.categories.get_loc(item_id)\n",
    "    distances, indices = knn_model.kneighbors(user_item_sparse.T.getrow(item_idx), n_neighbors=top_n+1)\n",
    "    rec_indices = indices.flatten()[1:]  # skip itself\n",
    "    return item_cat.cat.categories[rec_indices].tolist()\n",
    "\n",
    "print(\"KNN collaborative filtering model built.\")\n",
    "\n",
    "# Save recommenders dictionary\n",
    "with open(os.path.join(MODELS_DIR, \"recommender_functions.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        'recommend_content_based': recommend_content_based,\n",
    "        'recommend_collaborative_knn_sparse': recommend_collaborative_knn_sparse,\n",
    "    }, f)\n",
    "print(\"Models and recommenders saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c80d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
